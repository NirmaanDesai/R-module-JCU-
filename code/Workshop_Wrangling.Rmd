---
title: "Workshop 4"
output: html_document
date: "2024-05-15"
---

##Workshop 3:

#installing packages: tidyverse
```{r}
install.packages("rlang")
library(rlang)
library(tidyverse)
```


#Example below:

```{r}
table1
#> # A tibble: 6 × 4
#>   country      year  cases population
#>   <chr>       <int>  <int>      <int>
#> 1 Afghanistan  1999    745   19987071
#> 2 Afghanistan  2000   2666   20595360
#> 3 Brazil       1999  37737  172006362
#> 4 Brazil       2000  80488  174504898
#> 5 China        1999 212258 1272915272
#> 6 China        2000 213766 1280428583
table2
#> # A tibble: 12 × 4
#>   country      year type           count
#>   <chr>       <int> <chr>          <int>
#> 1 Afghanistan  1999 cases            745
#> 2 Afghanistan  1999 population  19987071
#> 3 Afghanistan  2000 cases           2666
#> 4 Afghanistan  2000 population  20595360
#> 5 Brazil       1999 cases          37737
#> 6 Brazil       1999 population 172006362
#> # ... with 6 more rows
table3
#> # A tibble: 6 × 3
#>   country      year rate             
#> * <chr>       <int> <chr>            
#> 1 Afghanistan  1999 745/19987071     
#> 2 Afghanistan  2000 2666/20595360    
#> 3 Brazil       1999 37737/172006362  
#> 4 Brazil       2000 80488/174504898  
#> 5 China        1999 212258/1272915272
#> 6 China        2000 213766/1280428583


```

#How we make our dataset tidy is by following three interrelated rules. Each variable must have its own column.Each observation must have its own row.Each value must have its own cell.


##Like below, we apply the function mutate to compute the rate given two variables.

```{r}
# Compute rate per 10,000
table1 %>% 
  mutate(rate = cases / population * 10000)
#> # A tibble: 6 × 5
#>   country      year  cases population  rate
#>   <chr>       <int>  <int>      <int> <dbl>
#> 1 Afghanistan  1999    745   19987071 0.373
#> 2 Afghanistan  2000   2666   20595360 1.29 
#> 3 Brazil       1999  37737  172006362 2.19 
#> 4 Brazil       2000  80488  174504898 5.61 
#> 5 China        1999 212258 1272915272 1.67 
#> 6 China        2000 213766 1280428583 1.67

# Compute cases per year
table1 %>% 
  count(year, wt = cases)
#> # A tibble: 2 × 2
#>    year      n
#>   <int>  <int>
#> 1  1999 250740
#> 2  2000 296920

# Visualise changes over time
library(ggplot2)
ggplot(table1, aes(year, cases)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))
```
##Excersise 4.4.1:
#For each of the sample tables, describe what each observation and each column represents.Sketch out the processes you would use to calculate the rate for table2 and table3. You will need to perform four operations:Extract the number of TB cases per country per year.Extract the matching population per country per year.Divide cases by population, and multiply by 10,000. Store back in the appropriate place Hint: you haven’t yet learned the functions you need to actually perform these, but you can still think through the transformations!


##Pivoting data to make it tidy:

#The second step is to resolve one of the two common problems with untidy data. These are:One variable is spread across multiple columns.One observation is scattered across multiple rows

##To fix these we will pivot our data (i.e. move it around) into tidy form using two functions in tidyr: pivot_longer() to lengthen data and pivot_wider() to widen data. Let’s explore these functions a bit further.

##4.5.1: Lenghtening datasets

##Using  pivot_longer() splits the dataset by column, and reformats it into the tidy format of observations as rows, columns as variables and values as cell entries. The dataset is now longer (more rows, at left) than the ‘wide format’ data on the right. 

##Example:
```{r}
billboard
view(billboard)
#> # A tibble: 317 × 79
#>   artist       track               date.entered   wk1   wk2   wk3   wk4   wk5
#>   <chr>        <chr>               <date>       <dbl> <dbl> <dbl> <dbl> <dbl>
#> 1 2 Pac        Baby Don't Cry (Ke... 2000-02-26      87    82    72    77    87
#> 2 2Ge+her      The Hardest Part O... 2000-09-02      91    87    92    NA    NA
#> 3 3 Doors Down Kryptonite          2000-04-08      81    70    68    67    66
#> 4 3 Doors Down Loser               2000-10-21      76    76    72    69    67
#> 5 504 Boyz     Wobble Wobble       2000-04-15      57    34    25    17    17
#> 6 98^0         Give Me Just One N... 2000-08-19      51    39    34    26    26
#> # ℹ 311 more rows
#> # ℹ 71 more variables: wk6 <dbl>, wk7 <dbl>, wk8 <dbl>, wk9 <dbl>, ...


```
#In this dataset, each observation is a song. The first three columns (artist, track and date.entered) are variables that describe the song. Then we have 76 columns (wk1-wk76) that describe the rank of the song in each week. Here, the column names are one variable (the week) and the cell values are another (the rank). To tidy the billboard dataset we will use pivot_longer().

#This is the case where actual data values (wk1, wk2 etc.)  are in the column name, with each observation (row of data) being a song. We need to have the data in a format where each row is an observation (so-called long format).

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
#> # A tibble: 24,092 × 5
#>    artist track                   date.entered week   rank
#>    <chr>  <chr>                   <date>       <chr> <dbl>
#>  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87
#>  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82
#>  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72
#>  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77
#>  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87
#>  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94
#>  #> # ℹ 24,082 more rows


```
#As you can see in the above code snippet, there are three key arguments to the pivot_longer() function: cols which specifies the columns you want to pivot (the ones that aren’t variables). Note: you could either use !c(artist, track, date.entered) OR starts_with('wk') because the cols argument uses the same syntax as select(). names_to which names the variable stored in the column names. We chose to name that variable week.values_to which names the variable stored in the cell values that we named rank

#Note that in the code "week" and "rank" are quoted because they are new variables that we are creating, they don’t exist yet in the data when we run the pivot_longer() call.

##Notice the NA values in the output above? It looks like “Baby Don’t Cry” by 2 Pac was only in the top 100 for 7 out of 76 weeks. Therefore, when we lengthened the data, the weeks where it wasn't on the charts became ‘NA.’ These NA’s were forced to exist because of the structure of the dataset not because they are actually unknown. Therefore, we can simply ask pivot_longer to remove them by adding the argument values_drop_na = TRUE as shown below:

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
#> # A tibble: 5,307 × 5
#>   artist track                   date.entered week   rank
#>   <chr>  <chr>                   <date>       <chr> <dbl>
#> 1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1      87
#> 2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2      82
#> 3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3      72
#> 4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4      77
#> 5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5      87
#> 6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6      94
#> # ℹ 5,301 more rows
```
##4.5.2: Pivoting longer

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)

```


###However, we want our new (tidy) dataset to have three variables: id (which already exists)measurement (the column names) value (the cell values).To make this happen we need to pivot df longer:

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
#> # A tibble: 6 × 3
#>   id    measurement value
#>   <chr> <chr>       <dbl>
#> 1 A     bp1           100
#> 2 A     bp2           120
#> 3 B     bp1           140
#> 4 B     bp2           115
#> 5 C     bp1           120
#> 6 C     bp2           125
```

#The left table represents what we originally typed when we created our dataset ‘df.’ The right table is what happened to the id when we used pivot_longer(). See how the data pivoted and repeated an id for each measurement? Additionally, the original column names in df (bp1 and bp2) now become values in a new variable, whose name is defined by the names_to argument and these values need to be repeated once for each row in the original dataset: And finally, the cell values also become a new variable with a name we defined by the values_to argument. These are unwound row by row:

##4.5.3: Widening datasets

###less common cases, we may need to widen a dataset rather than lengthen it. Widening is essentially the opposite of lengthening and we do so by using the function pivot_wider(). pivot_wider() allows us to handle an observation if it is scattered across multiple rows. Let’s visualize this in the image below:

```{r}
cms_patient_experience
#> # A tibble: 500 × 5
#>   org_pac_id org_nm                     measure_cd   measure_title   prf_rate
#>   <chr>      <chr>                      <chr>        <chr>              <dbl>
#> 1 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_1  CAHPS for MIPS...       63
#> 2 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_2  CAHPS for MIPS...       87
#> 3 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_3  CAHPS for MIPS...       86
#> 4 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_5  CAHPS for MIPS...       57
#> 5 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_8  CAHPS for MIPS...       85
#> 6 0446157747 USC CARE MEDICAL GROUP INC CAHPS_GRP_12 CAHPS for MIPS...       24
#> # ℹ 494 more rows

```
```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
#> # A tibble: 6 × 2
#>   measure_cd   measure_title                                                 
#>   <chr>        <chr>                                                         
#> 1 CAHPS_GRP_1  CAHPS for MIPS SSM: Getting Timely Care, Appointments, and In...
#> 2 CAHPS_GRP_2  CAHPS for MIPS SSM: How Well Providers Communicate            
#> 3 CAHPS_GRP_3  CAHPS for MIPS SSM: Patient's Rating of Provider              
#> 4 CAHPS_GRP_5  CAHPS for MIPS SSM: Health Promotion and Education            
#> 5 CAHPS_GRP_8  CAHPS for MIPS SSM: Courteous and Helpful Office Staff        
#> 6 CAHPS_GRP_12 CAHPS for MIPS SSM: Stewardship of Patient Resources
```


###Neither of these columns will make particularly great variable names: measure_cd doesn’t hint at the meaning of the variable and measure_title is a long sentence containing spaces. We’ll use measure_cd as the source for our new column names for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.pivot_wider() has the opposite interface to pivot_longer(): instead of choosing new column names, we need to provide the existing columns that define the values (values_from) and the column name (names_from):

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )

```

###The above output doesn’t look quite right; we still seem to have multiple rows for each organization. That’s because, we also need to tell pivot_wider() which column or columns have values that uniquely identify each row; in this case those are the variables starting with "org":

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

##4.5.4:Pivoting wider

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

##We’ll take the names from the measurement column using the names_from() argument and the values from the value column using the values_from() argument:

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )

```


#To start the pivoting process, pivot_wider() needs to first figure out what will go in the rows and columns. The new column names will be the unique values of measurement.

```{r}
df |> 
  distinct(measurement) |> 
  pull()

```

###By default, the rows in the output are determined by all the variables that aren’t going into the new names or values. These are called the id_cols. Here there is only one column, but in general there can be any number.

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```
#pivot_wider() then combines these results to generate an empty dataframe:

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)

```

##4.5.5 Exercises
#Why are pivot_longer() and pivot_wider() not perfectly symmetrical? Carefully consider the following example. 
#stocks <- tibble(year   = c(2015, 2015, 2016, 2016),half  = c(   1,    2,     1,    2),return = c(1.88, 0.59, 0.92, 0.17))stocks %>% pivot_wider(names_from = year, values_from = return) %>% pivot_longer(`2015`:`2016`, names_to = "year", values_to = "return")(Hint: look at the variable types and think about column names) pivot_longer() has a names_ptypes argument, e.g.  names_ptypes = list(year = double()). What does it do?Why does this code fail?table4a %>% pivot_longer(c(1999, 2000), names_to = "year", values_to = "cases")
#> Error in `pivot_longer()`:
#> ! Can't subset columns past the end.
#> ℹ Locations 1999 and 2000 don't exist.
#> ℹ There are only 3 columns.


#Consider the sample tibble below. Do you need to make it wider or longer? What are the variables? preg <- tribble(~pregnant, ~male, ~female, "yes",     NA,    10, "no",      20,    12)

#4.5.6 Separating and uniting data tables

#In table3, we see one column (rate) that contains two variables (cases and population). To address this, we can use the separate() function which separates one column into multiple columns wherever you designate.

```{r}
table3
```

##We need to split the rate column up into two variables: 1) cases and 2) population. separate() will take the name of the column we want to split and the names of the columns we want it split into. See the code below:


```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"))
```

###Note from R4DS: By default, separate() will split values wherever it sees a non-alphanumeric character (i.e. a character that isn’t a number or letter). For example, in the code above, separate() split the values of rate at the forward slash characters. If you wish to use a specific character to separate a column, you can pass the character to the sep argument of separate(). For example, we could rewrite the code above as:


```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), sep = "/")
```

##Notice the data types in table3 above. Both cases and population are listed as character (<chr>) types. This is a default of using separate(). However, since the values in those columns are actually numbers, we want to ask separate() to convert them to better types using convert = TRUE. Now you can see they are listed as integer types(<int>)


```{r}
table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)
```
#You can use this arrangement to separate the last two digits of each year. This makes this data less tidy, but is useful in other cases, as you’ll see in a little bit.

##Using unite():To perform the inverse of separate() we will use unite() to combine multiple columns into a single column. In the example below for table5, we use unite() to rejoin century and year columns. unite() takes a data frame, the name of the new variable and a set of columns to combine using dplyr::select(). 

```{r}
table5 %>% 
  unite(new, century, year, sep = "")

```

#4.6 Handling missing values

#4.6.1 Explicit missing values

# common use for missing values is as a data entry convenience. When data is entered by hand, missing values sometimes indicate that the value in the previous row has been repeated (or carried forward):


```{r}
treatment <- tribble(
  ~person,           ~treatment, ~response,
  "Derrick Whitmore", 1,         7,
  NA,                 2,         10,
  NA,                 3,         NA,
  "Katherine Burke",  1,         4
)
```

#You can fill in these missing values with tidyr::fill(). It works like select(), taking a set of columns:

```{r}
treatment |>
  fill(everything())
```

####This treatment is sometimes called “last observation carried forward”, or locf for short. You can use the .direction argument to fill in missing values that have been generated in more exotic ways.


#4.6.2 Fixed values

```{r}
x <- c(1, 4, 5, 7, NA)
coalesce(x, 0)
#> [1] 1 4 5 7 0

```



##And sometimes you’ll encounter the opposite problem where some other concrete value actually represents a missing value. This typically happens when data is generated from an older software that can’t properly represent missing values so it uses something like 99 or -999 in place of the missing value. You can fix this with dplyr::na_if():


```{r}
x <- c(1, 4, 5, 7, -99)
na_if(x, -99)

```

##4.6.3 NaN

###One special type of missing value worth mentioning is NaN or Not a Number. It typically behaves the same as NA but in some rare cases you may need to distinguish it using is.nan(x):

```{r}
x <- c(NA, NaN)
x * 10
#> [1]  NA NaN
x == 1
#> [1] NA NA
is.na(x)
#> [1] TRUE TRUE

```
##4.6.4 Implicit missing values

#So far we’ve talked about missing values that are explicitly missing, i.e. you can see an NA in your data. But missing values can also be implicitly missing, if an entire row of data is simply absent from the data. Let’s illustrate the difference with a simple dataset that records the price of some stock each quarter:

```{r}
stocks <- tibble(
  year  = c(2020, 2020, 2020, 2020, 2021, 2021, 2021),
  qtr   = c(   1,    2,    3,    4,    2,    3,    4),
  price = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)
```

#This dataset has two missing observations:The price in the fourth quarter of 2020 is explicitly missing, because its value is NA.The price for the first quarter of 2021 is implicitly missing, because it simply does not appear in the dataset.Sometimes you want to make implicit missings explicit in order to have something physical to work with. In other cases, explicit missings are forced upon you by the structure of the data and you want to get rid of them. Remember how we did this when we used pivot_wider()?Here’s another example where if we pivot stocks wider to put the quarter in the columns, both missing values become explicit:

```{r}
stocks |>
  pivot_wider(
    names_from = qtr, 
    values_from = price
  )

```

#4.7 How can I import data into R?


##Student ID,Full Name,favourite.food,mealPlan,AGE 1,Sunil Huffmann,Strawberry yoghurt,Lunch only,4 2,Barclay Lynn,French fries,Lunch only,5 3,Jayendra Lyne,N/A,Breakfast and lunch,7 4,Leon Rossini,Anchovies,Lunch only, 5,Chidiegwu Dunkel,Pizza,Breakfast and lunch,five 6,Güvenç Attila,Ice cream,Lunch only,6


```{r}
? read_csv
students <- read_csv("C://data/students.csv")

```

###4.8 Learning relational data

###4.8.1 What is relational data? 
```{r}
#Simply put, relational data is a collection of multiple data tables in a given dataset or in a project that are related in some ways. These are called relational data because the relations between these tables matter, not just the individual tables, and will even be a key source of the insights you might be able to deliver. Many datasets will contain multiple data tables and the combination of data in these tables will help you to answer your questions of interest.Relations are always defined between a pair of tables. All other relations are built up from this simple idea: the relations of three or more tables are always a property of the relations between each pair. Sometimes both elements of a pair can be the same table! This is needed if, for example, you have a table of people, and each person has a reference to their parents.Here’s an example. You have a dataset of the number of people per country. Great, you can now plot the number of people per country. BUT what if you wanted to plot the number of people per continent? Here you could get another dataset that is the name of the countries according to which continent they are in. To start to summarise data by continent, you can join these datasets together, because you have one common variable (country). Once joined, you are set to now summarise by continent!To work with relational data you need verbs that work with pairs of tables. In the same way that ggplot2 is a package for implementing the grammar of graphics, dplyr is a package focused on the grammar of data manipulation. It’s a package specialised for doing data analysis. dplyr provides the following verbs to make common data analysis operations easier. The three families of verbs designed to work with relational data are:Mutating joins - add new variables to one dataframe from matching observations in another.Filtering joins - filter observations from one data frame based on whether or not they match an observation in the other tableSet operations - treat observations as if they are set elementsNote: dplyr makes common operations easier, though sometimes at the expense of making it more difficult to do other things that aren’t often needed for data analysis. So there are some tradeoffs, and you can read the textbook for the specific details of them. In practice, I am sure you’ll find these all very useful.

```

#Let’s explore relational data using the nycflight13 package dataset. You should already be familiar with this dataset from the Tibbles section (5.3). Make sure tidyverse and nycflights13 are loaded into your R library for this session.

```{r}
library(tidyverse)
install.packages("nycflights13")
library(nycflights13)
```

```{r}
airlines

```

#airports gives information about each airport, identified by the FAA airport code:
```{r}
airports

```

#4.6.1 Joining datasets

#A key is a variable (or set of variables) that uniquely identifies an observation. In simple cases, a single variable is sufficient to identify an observation. For example, each plane is uniquely identified by its tailnum. In other cases, multiple variables may be needed. For example, to identify an observation in weather you need five variables: year, month, day, hour, origin.The two types of keys are primary and foreign. It is possible for a variable to be both a primary and a foreign key depending on which pair of tables you’re considering. For example, origin is part of the weather primary key, and is also a foreign key for the airports table.A primary key uniquely identifies an observation in its own table. For example, planes$tailnum is a primary key because it uniquely identifies each plane in the planes table. A foreign key uniquely identifies an observation in another table. For example, flights$tailnum is a foreign key because it appears in the flights table where it matches each flight to a unique plane.Once you’ve identified the primary keys in your tables, it’s good practice to verify that they do indeed uniquely identify each observation. One way to do that is to count() the primary keys and look for entries where n is greater than one:

```{r}
planes %>% 
  count(tailnum) %>% 
  filter(n > 1)
#> # A tibble: 0 × 2
#> # ... with 2 variables: tailnum <chr>, n <int>

weather %>% 
  count(year, month, day, hour, origin) %>% 
  filter(n > 1)

```


#Sometimes a table doesn’t have an explicit primary key: each row is an observation, but no combination of variables reliably identifies it. For example, what’s the primary key in the flights table? You might think it would be the date plus the flight or tail number, but neither of those are unique:

```{r}
flights %>% 
  count(year, month, day, flight) %>% 
  filter(n > 1)
#> # A tibble: 29,768 × 5
#>    year month   day flight     n
#>   <int> <int> <int>  <int> <int>
#> 1  2013     1     1      1     2
#> 2  2013     1     1      3     2
#> 3  2013     1     1      4     2
#> 4  2013     1     1     11     3
#> 5  2013     1     1     15     2
#> 6  2013     1     1     21     2
#> # ... with 29,762 more rows

flights %>% 
  count(year, month, day, tailnum) %>% 
  filter(n > 1)
#> # A tibble: 64,928 × 5
#>    year month   day tailnum     n
#>   <int> <int> <int> <chr>   <int>
#> 1  2013     1     1 N0EGMQ      2
#> 2  2013     1     1 N11189      2
#> 3  2013     1     1 N11536      2
#> 4  2013     1     1 N11544      3
#> 5  2013     1     1 N11551      2
#> 6  2013     1     1 N12540      2
#> # ... with 64,922 more rows
```


#4.6.2 Mutating joins
#Join functions (like the base mutate()) add variables to the right side of your data table so sometimes you’ll need to change the view of your screen to see them all. (Remember your tibble skills! Set your global options!) Or you can view them on a new tab entirely with View() in R studio. First we are going to create a narrower subset of the data from nycflights13 just so that it’s easier to see the variables being added one one screen:

```{r}
flights2 <- flights %>% 
  select(year:day, hour, origin, dest, tailnum, carrier)

```

#Now we will see what happens when we use the mutating function left_join()
```{r}
flights2 %>%
  select(-origin, -dest) %>% 
  left_join(airlines, by = "carrier")

```

#Here, we have asked it to add the full airline name to the flights2 data by combining the airlines and flights2 data frames with left_join(). Notice the column name has been added on the right and contains the carrier’s full name. Now, we could have gotten to this same result using the R base mutate() function (see code below), but notice that the code is much more involved and can get messy when matching multiple variables. This is why we use a “mutating join” to make life a little easier.

```{r}
flights2 %>%
  select(-origin, -dest) %>% 
  mutate(name = airlines$name[match(carrier, airlines$carrier)])

```

#Let’s dive into how mutating joins work in detail. Visual representations are a handy tool for conceptualising these joins. 
```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y3"
)


```

#There are two categories of joins: inner and outer. The inner join is the simplest join as it matches observations with equivalent keys. The visualisation above is an inner join and more specifically an equijoin because the keys are matched using the equality operator “=”. (Note: most joins are equijoins so this specification isn’t strictly necessary.)The most important property of an inner join is that unmatched rows are not included in the result. This means that generally inner joins are usually not appropriate for use in analysis because it’s too easy to lose observations.The output of an inner join is a new data frame that contains the key, the x values, and the y values. We use ‘by’ to tell dplyr which variable is the key:

```{r}
x %>% 
  inner_join(y, by = "key")

```

#So far all the diagrams have assumed that the keys are unique. But that’s not always the case. This section explains what happens when the keys are not unique. There are two possibilities:One table has duplicate keys. This is useful when you want to add in additional information as there is typically a one-to-many relationship.

```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     1, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2"
)
left_join(x, y, by = "key")
#> # A tibble: 4 × 3
#>     key val_x val_y
#>   <dbl> <chr> <chr>
#> 1     1 x1    y1   
#> 2     2 x2    y2   
#> 3     2 x3    y2   
#> 4     1 x4    y1


```

###2. Both tables have duplicate keys. This is usually an error because in neither table do the keys uniquely identify an observation. When you join duplicate keys, you get all possible combinations, the Cartesian product:


```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     2, "x3",
     3, "x4"
)
y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     2, "y3",
     3, "y4"
)
left_join(x, y, by = "key")
#> # A tibble: 6 × 3
#>     key val_x val_y
#>   <dbl> <chr> <chr>
#> 1     1 x1    y1   
#> 2     2 x2    y2   
#> 3     2 x2    y3   
#> 4     2 x3    y2   
#> 5     2 x3    y3   
#> 6     3 x4    y4


```

##So far, the pairs of tables have always been joined by a single variable, and that variable has the same name in both tables. That constraint was encoded by by = "key". You can use other values for by to connect the tables in other ways: The default, by = NULL, uses all variables that appear in both tables, the natural join. For example, the flights and weather tables match on their common variables: year, month, day, hour and origin.

```{r}
flights2 %>% 
  left_join(weather)

```

##A named character vector: by = c("a" = "b"). This will match variable a in table x to variable b in table y. The variables from x will be used in the output. For example, if we want to draw a map (this will be relevant for our mapping workshop!) We need to combine the flights data with the airports data which contains the location (lat and lon) of each airport. Each flight has an origin and destination airport, so we need to specify which one we want to join to:


```{r}
flights2 %>% 
  left_join(airports, c("dest" = "faa"))

```

#4.6 Pipes for more readable workflows

